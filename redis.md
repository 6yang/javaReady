# 一  常见面试题



## 1  缓存中间件——Memcache和Redis的区别

​	

## 2为什么Redis性能这么好



​	**10w+QPS（QPS即query per second，每秒内查询次数）**

- 完全基于内存 绝大部分请求是纯粹的内存操作 ，执行效率高
- 数据结构简单，对数据操作也简单，存储结构就是键值对
- 采用单线程，单线程也能处理高并发请求，想多核也可启动多实例，不会有并发的冲突问题，效率更高（并发 != 并行）
- 使用多路IO复用模型，非阻塞IO

### 1.3.3 Redis采用的IO多路复用函数

- ​	 因地制宜，根据平台的不同选择不同的函数


- ​	 优先选择时间复杂度为O(1)的IO多路复用函数作为底层实现


- ​	 以时间复杂度为O(n)的select作为保底


- ​	 基于react设计模式监听IO事件

## 3.  redis 常用数据类型

- String：最基本的数据类型，二进制安全（可包含任何数据），最大存储512MB

- Hash：String 元素组成的字典，适合用于存储对象
- List：列表，按照String元素插入顺序排序
  - List是后进先出的，类似于栈，能存储约40亿成员
- Set：String元素组成的无序集合，通过哈希表实现，不允许重复
- Sorted Set：通过分数来为集合中的成员进行从小到大的排序
- HyperLogLog：用于计数的，
- Geo :用于支持存储地理位置信息的

## 4. 从海量Key里查询出某一固定前缀的key

**摸清数据规模，即问清楚边界** 

1. **使用keys partten** 

   ​	· KEYS指令**一次性返回所有匹配的Key**

   ​	· 键的数量过大会使服务卡顿

    redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复

    

2. **使用SCAN cursor [MATCH pattern] [COUNT count]**

    scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。 



## 5、如何实现分布式锁

 	**SETNX KEY value：如果key不存在，则创建并赋值（Set if Not Exist）**

​	先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。



​	 **如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？**

​		这个锁永远也不会释放 	

 	**缺点**：<u>原子性得不到满足</u>（如果执行if语句时宕机，则其他机器永远得不到key）

**解决办法**

 <u>set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的</u> 

 	使用**SET key value [EX seconds] [PX milliseconds] [NX|XX]**

​	  EX seconds：设置键的过期时间为 second 秒

​	· PX millisecond：设置键的过期时间为 millisecond 毫秒

​	· NX：只有键不存在时，才对键进行设置操作（效果等同于SETNX）

​	· XX：只在键已经存在时，才对键进行设置操作



## 6. 大量的key同时过期注意事项

​	 **集中过期，由于清除大量的key很耗时，会出现短暂的卡顿现象**

​	· **解决方案**：在设置key的过期时间的时候， 一般需要在时间上加一个随机值，使得过期时间分散一些。

 

## 7. **使用过Redis做异步队列么，你是怎么用的？** 

​	

使用List作为队列，RPUSH生产消息，LPOP消费消息 ,当lpop没有消息的时候，要适当sleep一会再重试。

![](E:\code\review\own\img\Snipaste_2020-02-22_13-06-42.png)

**可不可以不用sleep呢？**list还有个指令叫**blpop**，在没有消息的时候，它会阻塞住直到消息到来。

​	<u>缺点：只能供一个消费者消费</u>

![](E:\code\review\own\img\Snipaste_2020-02-22_13-05-29.png)

**能不能生产一次消费多次呢**？使用pub/sub主题订阅者模式，可以实现1:N的消息队列。

​	· 发送者（pub）发送消息，订阅者（sub）接收消息

​	· 订阅者可以订阅任意数量的频道

![](E:\code\review\own\img\Snipaste_2020-02-22_13-06-17.png)

 **缺点**：在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。 



 **redis如何实现延时队列？**

使用sorted set，拿时间戳作为score，消息内容作为key 调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 



## 8 . Redis的持久化方式优缺点

​	

- RDB（快照）持久化：保存某个时间点的全量数据快照
- AOF（Append-Only-File）持久化：保存写状态

> RDB 优点

- RDB 是一种表示某个即时点的 Redis 数据的紧凑文件。RDB 文件适合用于备份。例如，你可能想要每小时归档最近 24 小时的 RDB 文件，每天保存近 30 天的 RDB 快照。这允许你很容易的恢复不同版本的数据集以容灾。
- RDB 非常适合于灾难恢复，作为一个紧凑的单一文件，可以被传输到远程的数据中心，或者是 Amazon S3(可能得加密)。
- RDB 最大化了 Redis 的性能，因为 Redis 父进程持久化时唯一需要做的是启动(fork)一个子进程，由子进程完成所有剩余工作。父进程实例不需要执行像磁盘 IO 这样的操作。
- RDB 在重启保存了大数据集的实例时比 AOF 要快。

> RDB 缺点

- 当你需要在 Redis 停止工作(例如停电)时最小化数据丢失，RDB 可能不太好。你可以配置不同的保存点。然而，你通常每隔 5 分钟或更久创建一个 RDB 快照，所以一旦 Redis 因为任何原因没有正确关闭而停止工作，你就得做好最近几分钟数据丢失的准备了。
- RDB 需要经常调用 fork()子进程来持久化到磁盘。如果数据集很大的话，fork()比较耗时，结果就是，当数据集非常大并且 CPU 性能不够强大的话，Redis 会停止服务客户端几毫秒甚至一秒。AOF 也需要 fork()，但是你可以调整多久频率重写日志而不会有损(trade-off)持久性(durability)。

AOF 优点

- 使用 AOF Redis 会更具有可持久性(durable)：你可以有很多不同的 fsync 策略：没有 fsync，每秒 fsync，每次请求时 fsync。使用默认的每秒 fsync 策略，写性能也仍然很不错(fsync 是由后台线程完成的，主线程继续努力地执行写请求)，即便你也就仅仅只损失一秒钟的写数据。
- AOF 日志是一个追加文件，所以不需要定位，在断电时也没有损坏问题。即使由于某种原因文件末尾是一个写到一半的命令(磁盘满或者其他原因),redis-check-aof 工具也可以很轻易的修复。
- AOF 文件里面包含一个接一个的操作，以易于理解和解析的格式存储。你也可以轻易的导出一个 AOF 文件。例如，即使你不小心错误地使用 FLUSHALL 命令清空一切，如果此时并没有执行重写，你仍然可以保存你的数据集，你只要停止服务器，删除最后一条命令，然后重启 Redis 就可以。

AOF 缺点

- 对同样的数据集，AOF 文件通常要大于等价的 RDB 文件。
- AOF 可能比 RDB 慢，这取决于准确的 fsync 策略。通常 fsync 设置为每秒一次的话性能仍然很高，如果关闭 fsync，即使在很高的负载下也和 RDB 一样的快。不过，即使在很大的写负载情况下，RDB 还是能提供能好的最大延迟保证。

## 9. Redis如何做持久化的？

bgsave做镜像全量持久化，aof做增量持久化。

因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态。



 **那如果突然机器掉电会怎样？**

取决于aof日志appendfsync属性的配置

如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。

但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。

 **bgsave的原理是什么？** 

> 1.redis调用系统的fork()函数创建一个子进程
>  2.子进程将数据集写入一个临时的RDB文件
>  3.当子进程完成对临时的RDB文件的写入时，redis用新的RDB文件来替换原来旧的RDB文件，并将旧的RDB文件删除

**fork()** and **copy on write**（写时复制）

 fork是指redis通过创建子进程来进行bgsave操作，防止bgsave 的过程中阻塞主线程

copy on write是指，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 



## 10 . **Pipeline有什么好处，为什么要用pipeline？** 

 **可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。**

使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。 



##  **11. Redis的同步机制了解么？** 

<img src="E:\code\review\own\img\Snipaste_2020-02-22_14-39-41.png" style="zoom: 33%;" />

 **Redis可以使用主从同步，从从同步** 

 主从第一次连接的时候，进行全量同步；

全同步结束后，进行增量同步。

当然，如果有需要，slave 在任何时候都可以发起全量同步。

**redis 策略是**，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。 



**全量同步：**

　Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下：
　　1）从服务器连接主服务器，发送SYNC命令；
　　2）主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；
　　3）主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；
　　4）从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；
　　5）主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；
　　6）从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；

​	![](E:\code\review\own\img\Snipaste_2020-02-22_14-39-54.png)

**增量同步**

 Redis增量复制是指Slave初始化后开始正常工作时，主服务器发生的写操作同步到从服务器的过程。
增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。 



## 12.  **是否使用过Redis集群，集群的原理是什么？** 

Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。

Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。

 集群要实现的目的是要将不同的 key 分散放置到不同的 redis 节点 

**redis引入了 哈希槽 的概念。** 

Redis集群有 16384 (2^14)个哈希槽，每个key通过 CRC16 校验后 对16384取模 来决定放置哪个槽(Slot)，集群的每个节点负责一部分hash槽。

这种结构很容易添加或者删除节点，并且无论是添加删除或者修改某一个节点，都不会造成集群不可用的状态。

**使用哈希槽的好处**就在于可以方便的添加或移除节点。

当需要增加节点时，只需要把其他节点的某些哈希槽挪到新节点就可以了；

当需要移除节点时，只需要把移除节点上的哈希槽挪到其他节点就行了；

在这一点上，我们以后 **新增或移除节点的时候不用先停掉所有的 redis 服务。**



## 13. redis 的Zset 是如何实现的

[使用了跳表的实现方式](https://zsr.github.io/2017/07/03/redis-zset%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0/)

### 13.1  跳表和红黑树的区别 

- 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
- 更容易实现；
- 支持无锁操作



## 14 redis 的数据淘汰Redis5.0

（1）volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰。

（2）volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰。

（3）volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。

（4）volatile-lfu：从已设置过期时间的数据集挑选使用频率最低的数据淘汰。

（5）allkeys-lru：从数据集中挑选最近最少使用的数据淘汰

（6）allkeys-lfu：从数据集中挑选使用频率最低的数据淘汰。

（7）allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰

（8） no-enviction（驱逐）：禁止驱逐数据，这也是默认策略。意思是当内存不足以容纳新入数据时，新写入操作就会报错，请求可以继续进行，线上任务也不能持续进行，采用no-enviction策略可以保证数据不被丢失。