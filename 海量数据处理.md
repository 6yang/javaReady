## 1、共同的url

**例1：给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，找出a、b文件共同的url?**

> 50亿*64字节/1024/1024/1024 = 300G

**解法**：分治算法

> #### step1
>
> 遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件(记为a0,a1,...,a999，每个小文件约300M)，为什么是1000？主要根据内存大小和要分治的文件大小来计算，我们就大致可以把320G大小分为1000份，每份大约300M。
>
> #### step2
>
> 遍历文件b，采取和a相同的方式将url分别存储到1000个小文件(记为b0,b1,...,b999)。
>
> 文件a的hash映射和文件b的hash映射函数要保持一致，这样的话相同的url就会保存在对应的小文件中。比如，如果a中有一个url记录data1被hash到了a99文件中，那么如果b中也有相同url，则一定被hash到了b99中。
>
> 所以现在问题转换成了：找出1000对小文件中每一对相同的url（不对应的小文件不可能有相同的url）
>
> #### step3
>
> 因为每个小文件大约300M，所以我们再可以用
>
> 堆排序法
> 分治策略
> BitMap(位图法)

### 堆排序法

堆排序是4种平均时间复杂度为nlogn的排序方法之一，其优点在于当求M个数中的前n个最大数，和最小数的时候性能极好。所以当从海量数据中要找出前m个最大值或最小值，而对其他值没有要求时，使用堆排序法效果很好。

> 从1亿个整数里找出100个最大的数

- 读取前100个数字，建立最小堆。
- 依次读取余下的数，与最小堆作比较，维持最大值堆。可以每次读取的数量为一个磁盘页面，将每个页面的数据依次进堆比较，这样节省IO时间。
- 将堆进行排序，即可得到100个有序最大值。

这里采用堆排序将空间复杂度讲得很低，要排序1亿个数，但一次性只需读取100个数字，或者设置其他基数，不需要一次性读完所有数据，降低对内存要求。

### 分治策略

总体思想：分而治之。通过分治将大数据变成小数据进行处理，再合并。

首先区分内部排序和外部排序：

- 内部排序：内部排序是指待排序序列可以全部装入内存的排序过程，适用于规模较小的元素序列。
- 外部排序：外部排序是指大文件的排序，即待排序的记录存储在外存储器上，待排序的文件无法一次装入内存，需要在内存和外部存储器之间进行多次数据交换，才能达到排序整个文件的目的。

步骤：

- 从大数据中抽取样本，将需要排序的数据切分为多个样本数大致相等的区间
- 将大数据文件切分为多个小数据文件，这里要考虑IO次数和硬件资源问题，例如可将小数据文件数设定为1G（要预留内存给执行时的程序使用）
- 使用最优的算法对小数据文件的数据进行排序，将排序结果按照步骤1划分的区间进行存储
- 对各个数据区间内的排序结果文件进行处理，最终每个区间得到一个排序结果的文件
- 将各个区间的排序结果合并

其次要注意待排序数据的特点。如果待排序数据具有某些特点，往往能够有更加有效的方法解决。 同时，这种思想也更加贴近大数据应用的思维方式。

### BitMap(位图法)

32位机器上，一个整形，比如int a; 在内存中占32bit位，可以用对应的32bit位对应十进制的0-31个数，BitMap算法利用这种思想处理大量数据的排序与查询.

其优点是运算效率高，不许进行比较和移位，且占用内存少，比如N=10000000；只需占用内存为N/8=1250000Byte=1.25M。

https://blog.csdn.net/v_JULY_v/article/details/7382693